<!DOCTYPE html>
<html>
    <head>
        <title>Next Word Prediction - Dokumentation</title>
        <link rel="stylesheet" href="style.css">
        <link rel="stylesheet" href="prism.css">
        <script src="https://code.iconify.design/2/2.1.0/iconify.min.js"></script>

    </head>
    <body>
        <main class="index">
            <header class="nav-nav-header">
              <div class="title">
                <h1> Language Model mit RNN - Dokumentation</h1>
              </div>
              <a href="/">
                <button>
                  <div class="label">Back to the app</div>
                </button>
              </a>
            </header>
        <div class="content">
          <a href="https://github.com/VerrroS/rnn" id="github" target="_blank"><span class="iconify" data-icon="akar-icons:github-fill"></span></a>
          <p>Die Applikation ermöglicht es der nutzenden Person eine Eingabe in das Textfeld zu machen. Aufgrund dieser Eingabe werden die nächsten Wörter vorhergesagt. Auch die Anzahl der 
            zu vorhersagenden Worte kann eingestellt werden. Es wurden zwei verschiedene Modelle trainiert, ein RNN (Recurrent Neural Network) und ein FFNN (Feed Forward Neural Network). 
            Die Modelle können mit dem Toggle Button ausgewählt werden.
            Die beiden Wortvorhersagemodelle wurden mit Python in einem Jupyter Notebook trainiert und anschließened als json Datein für 
            TensorFlowjs gespeichert. Als Trainingsdaten wurden die ersten 2500 Wörter aus dem Buch
            <a href="https://archive.org/details/adventures_holmes">"The Adventures of Sherlock Holmes"</a> von Sir Arthur Conan Doyle verwendet.
          </p>
          <h2>Verwendete Frameworks</h2>
          <h3>Modell Training</h3>
          <ul>
            <li><a href="https://www.tensorflow.org/api_docs/python/tf/keras">TensorFlow Keras</a><br><p>Mit der TensorFlow Keras API können die Deep Learning
              Modelle erstellt und trainiert werden.
            </p></li>
            <li><a href="https://pypi.org/project/tensorflowjs/">TensorFlowjs</a> <br><p>Das trainierte Modell wird mithilfe von TensorFlowjs im Json 
              Format gespeichert. So ist es möglich das Modell in der Web Applikation zu verwenden.
            </p></li>
            <li><a href="https://numpy.org/">Numpy</a> <br><p>Numpy wurde für die Datenverarbeitung und -manipulation verwendet, insbesondere bei der Aufteilung des Texts in Sequenzen und beim Padding der Sequenzen.</p></li>
          </ul>
          <h3>Web Applikation</h3>
          <ul>
            <li><a href="https://www.tensorflow.org/js">Tensorflow.js</a><br><p>TensorFlow.js wird verwendet um die beiden Modelle in der Web Applikation
              zu laden und die Vorhersagen zu machen.</p></li>
            <li><a href="https://iconify.design/">Iconify</a><br><p>Iconify ist eine große Icon Bibliothek. </p></li>
          </ul>
        <h2>Tokenizer</h2>
        <img src="images/wörterZuZahlen.png" alt="Tokenizer" width="100%">
        <p>
          Die Textdaten wurden zunächst in Zahlen umgewandelt, um sie für das neuronale Netzwerk zugänglich zu machen. 
          Dabei wurde der Text anhand seiner Zeilenumbrüche aufgeteilt. Diese Aufteilung wurde gewählt, da sie in vielen 
          Textdatensätzen eine natürliche Trennung der Absätze ermöglicht. Dadurch können wir das Modell darauf trainieren, 
          die Wahrscheinlichkeit des nächsten Wortes basierend auf den vorherigen Worten in einem zusammenhängenden Text zu schätzen.
          Für jede Zeile werden dann die aufeinanderfolgenden Wörter in ein Array geschrieben. Am Beispielsatz "Das ist ein Beispielsatz"
          würden die Arrays [Das, ist] [Das, ist, ein] [Das, ist, ein, Beispielsatz] entstehen. Die Wörter werden One-hot codiert. Anschließend
          bekommen die Arrays ein Padding, sodass alle Arrays die gleiche Länge haben. </p>
          <pre><code class="language-python">
              input_sequences = []
              for line in text.split('\n'):
                  token_list = tokenizer.texts_to_sequences([line])[0]
                  for i in range(1, len(token_list)):
                  n_gram_sequence = token_list[:i+1]
                  input_sequences.append(n_gram_sequence)

              max_sequence_len = max([len(seq) for seq in input_sequences])
              input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))
          </code></pre>
          <img src="images/padding.png">
          <p>Gelernt wird dann, dass nach den Wörtern "Das ist" das Wort "ein" folgt und nach "Das ist ein" das Wort
          "Beispielsatz" folgt.
        </p>
        <img src="images/lernen.png">
        <h2>RNN Architektur</h2>
        <pre>
          <code class="language-python">
            model = Sequential()
            model.add(Embedding(total_words, 300, input_length=max_sequence_len-1))
            model.add(LSTM(300))
            model.add(Dense(total_words, activation='softmax'))

            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
            model.fit(X, y, epochs=100, verbose=1)
          </code>
        </pre>
        <p>
          Das Modell besteht aus einem Embedding Layer, einem LSTM Layer und einem Dense Layer.
          Der Embedding Layer ist ein Lookup Layer, der die Wörter in Vektoren umwandelt.
          Der LSTM Layer ist ein RNN Layer, der die Vektoren sequentiell verarbeitet.
          Der Dense Layer ist ein Fully Connected Layer, der die Ausgabe des LSTM Layers in die Anzahl der Wörter umwandelt.
          Die Anzahl der Neuronen wurden durch ausprobieren ermittelt.
        </p>
        <table>
            <tr>
              <th>Neuronen im Embedding Layer</th>
              <th>Neuronen im LSTM Layer</th>
              <th>Epochs</th>
              <th>Testergebnis (k=2)</th>
            </tr>
            <tr>
              <td>150</td>
              <td>150</td>
              <td>200</td>
              <td>2,53</td>
            </tr>
            <tr>
              <td>100</td>
              <td>300</td>
              <td>200</td>
              <td>2,53</td>
            </tr>
            <tr>
              <td>300</td>
              <td>300</td>
              <td>100</td>
              <td>4,04</td>
            </tr>
            <tr>
              <td>300</td>
              <td>600</td>
              <td>100</td>
              <td>2,53</td>
            </tr>
            <tr>
              <td>400</td>
              <td>400</td>
              <td>100</td>
              <td>3,28</td>
            </tr>
            <tr class="highlight">
              <td>400</td>
              <td>400</td>
              <td>200</td>
              <td>4,29</td>
            </tr>
          </table>
        <h2>FFNN Architektur</h2>
        <pre>
          <code class="language-python">
            model = Sequential()
            model.add(Dense(150, input_shape=(max_sequence_len-1,), activation='relu'))
            model.add(Dense(300, activation='relu'))
            model.add(Dense(300, activation='relu'))
            model.add(Dense(300, activation='relu'))
            model.add(Dense(300, activation='relu'))
            model.add(Dense(150, activation='relu'))
            model.add(Dense(total_words, activation='softmax'))
            
            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
            model.fit(X, y, epochs=100, verbose=1)
          </code>
        </pre>
        <p>
          Eine alternative Architektur, das Feedforward Neural Network (FFNN), wurde ebenfalls verwendet. 
          Dieses Netzwerk besteht aus mehreren Dense-Schichten, die sequenzielle Daten direkt verarbeiten. 
          Auch die Architektur des FFNN wurde durch ausprobieren ermittelt.
        </p>
        <table>
            <tr>
              <th>Neuronen im Input Layer</th>
              <th>Anzahl Hidden Layer</th>
              <th>Neuronen in Hidden Layers</th>
              <th>Epochs</th>
              <th>Testergebnis (k=2)</th>
            </tr>
            <tr>
              <td>150</td>
              <td>5</td>
              <td>300</td>
              <td>150</td>
              <td>2,02</td>
            </tr>
            <tr>
              <td>150</td>
              <td>10</td>
              <td>100</td>
              <td>200</td>
              <td>2,27</td>
            </tr>
            <tr>
              <td>150</td>
              <td>2</td>
              <td>150</td>
              <td>150</td>
              <td>2,78</td>
            </tr>
            <tr>
              <td>300</td>
              <td>10</td>
              <td>300</td>
              <td>150</td>
              <td>2,02</td>
            </tr>
            <tr class="highlight">
              <td>300</td>
              <td>2</td>
              <td>600</td>
              <td>100</td>
              <td>3,79</td>
            </tr>
            <tr>
              <td>600</td>
              <td>2</td>
              <td>800</td>
              <td>100</td>
              <td>1,52</td>
            </tr>
          </table>
        <h2>Vorhersage</h2>
        <p>Die Vorhersage wird mit dem predict() Befehl von TensorFlowjs gemacht. Dabei wird der Eingabetext
          verwendet um die nächsten Wörter vorherzusagen. Die Anzahl der vorhergesagten Wörter kann mit dem Slider eingestellt werden.
          Das Eingabewort wird verwendet, um das nächste Wort vorherzusagen, und der generierte Text wird als neue Eingabe verwendet, 
          um das darauf folgende Wort vorherzusagen. Dieser Prozess wird so oft wiederholt, wie von der nutzenden Person festgelegt. Die Vorhersagen 
          basieren auf den Wahrscheinlichkeiten, die das Modell für jedes mögliche Wort berechnet.
          <pre>
            <code class="language-javascript">
              async predictNextWordsUsingModel(inputText, numWords) {
                //console.log(typeof inputText)
                const tokenizer = new Tokenizer();
                    await tokenizer.initialize();
                    for (let i = 0; i < numWords; i++) {
                        const tokenList = await tokenizer.textsToSequences(inputText);
                        const paddedTokenList = await tokenizer.padSequences([tokenList]);
                        let predicted = this.model.predict(tf.tensor(paddedTokenList), [1, 1]);
                        let predictedIndex = argMax(predicted.dataSync());
                        let outputWord = await tokenizer.getWordByIndex(predictedIndex);
                        inputText += " " + outputWord;
                        //console.log(inputText);
                    }
                return inputText;
                }
            </code>
          </pre>
        <h2>Testen</h2>
        <p>Die Modelle können getestet werden, indem gezählt wird, wie oft die richtige Vorhersage in den als nächstes vorhergesagten Wörtern 
          vorkommt. Dabei hat die nutzende Person die Möglichkeit die Anzahl der vorhergesagten Wörter zu bestimmen. Der Text, der zum Testen verwendet wird,
          ist ein unbekannter Teil des selben Buches, das zum Trainieren verwendet wurde. Die Testfunktion gibt die Wahrscheinlichkeit aus, dass das richtige Wort
          in den nächsten vorhergesagten Wörtern enthalten ist.
          <pre>
            <code class="language-javascript">
              async function predictValidationData(validationData, nextWords) {
                let rightCounter = 0;
                let total = 0;
                let progress = 0;
                for (let i = 0; i < validationData.length - 1; i++) { 
                    const word = validationData[i];
                    const nextWord = validationData[i + 1]; 
                    let predictedWords = await currentModel.predictNextWordsUsingModel(word, nextWords);
                    predictedWords = predictedWords.split(" ")
                    predictedWords = Array.from(predictedWords);
                    if (predictedWords.includes(nextWord)) {
                        rightCounter++;
                    }
                    total++;
                    progress = Math.round((i / validationData.length) * 100);
                    progressbar.style.width = `${progress}%`;
                }
                probability = Math.round((rightCounter / total) * 10000) / 100;
                score.innerHTML = `The probability that the right next word is in the ${nextWords} next predicted words is ${probability}%`;
            }
            </code>
          </pre>
        </p>
        <h2>Ressourcen</h2>
        <ul>
          <li><a href="https://medium.com/@andrew.w.sale/deploying-text-classification-from-keras-to-tensorflow-js-92c614dca4ec">Tutorial für die Interation von TensorFlow Keras in JavaScript</a></li>
          <li><a href="">Tutorial zum Trainieren eines Prediction Models mit TensorFlow Keras</a></li>
        </ul>
        </div>
          </main>

          <script src="prism.js"></script>
    </body>
</html>